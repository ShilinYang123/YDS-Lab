#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YDS-Lab é›†æˆç®¡ç†å·¥å…·
æä¾›ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆã€APIè¿æ¥ã€æ•°æ®åŒæ­¥å’Œé›†æˆæµ‹è¯•åŠŸèƒ½
é€‚é…YDS-Labé¡¹ç›®ç»“æ„å’ŒAI Agentåä½œéœ€æ±‚
"""

import os
import sys
import json
import asyncio
import aiohttp
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, Callable
from datetime import datetime, timedelta
import logging
from dataclasses import dataclass, asdict, field
from enum import Enum
import hashlib
import base64
from urllib.parse import urljoin, urlparse
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

try:
    import jwt
    JWT_AVAILABLE = True
except ImportError:
    JWT_AVAILABLE = False

try:
    from cryptography.fernet import Fernet
    CRYPTO_AVAILABLE = True
except ImportError:
    CRYPTO_AVAILABLE = False

try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

try:
    import pika
    RABBITMQ_AVAILABLE = True
except ImportError:
    RABBITMQ_AVAILABLE = False

class IntegrationType(Enum):
    """é›†æˆç±»å‹æšä¸¾"""
    REST_API = "rest_api"
    GRAPHQL = "graphql"
    WEBHOOK = "webhook"
    DATABASE = "database"
    MESSAGE_QUEUE = "message_queue"
    FILE_STORAGE = "file_storage"
    AUTHENTICATION = "authentication"
    PAYMENT = "payment"
    EMAIL = "email"
    SMS = "sms"
    ANALYTICS = "analytics"
    MONITORING = "monitoring"
    CUSTOM = "custom"

class AuthType(Enum):
    """è®¤è¯ç±»å‹æšä¸¾"""
    NONE = "none"
    API_KEY = "api_key"
    BEARER_TOKEN = "bearer_token"
    BASIC_AUTH = "basic_auth"
    OAUTH2 = "oauth2"
    JWT = "jwt"
    CUSTOM = "custom"

class SyncDirection(Enum):
    """åŒæ­¥æ–¹å‘æšä¸¾"""
    PULL = "pull"  # ä»å¤–éƒ¨æ‹‰å–æ•°æ®
    PUSH = "push"  # æ¨é€æ•°æ®åˆ°å¤–éƒ¨
    BIDIRECTIONAL = "bidirectional"  # åŒå‘åŒæ­¥

class IntegrationStatus(Enum):
    """é›†æˆçŠ¶æ€æšä¸¾"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    ERROR = "error"
    TESTING = "testing"
    MAINTENANCE = "maintenance"

@dataclass
class AuthConfig:
    """è®¤è¯é…ç½®"""
    auth_type: AuthType
    credentials: Dict[str, Any] = field(default_factory=dict)
    headers: Dict[str, str] = field(default_factory=dict)
    params: Dict[str, str] = field(default_factory=dict)
    token_refresh_url: Optional[str] = None
    token_expires_at: Optional[datetime] = None

@dataclass
class EndpointConfig:
    """ç«¯ç‚¹é…ç½®"""
    url: str
    method: str = "GET"
    headers: Dict[str, str] = field(default_factory=dict)
    params: Dict[str, Any] = field(default_factory=dict)
    data: Optional[Dict[str, Any]] = None
    timeout: int = 30
    retry_count: int = 3
    retry_delay: float = 1.0

@dataclass
class DataMapping:
    """æ•°æ®æ˜ å°„é…ç½®"""
    source_field: str
    target_field: str
    transform_function: Optional[str] = None
    default_value: Any = None
    required: bool = False

@dataclass
class SyncConfig:
    """åŒæ­¥é…ç½®"""
    direction: SyncDirection
    schedule: Optional[str] = None  # cronè¡¨è¾¾å¼
    batch_size: int = 100
    data_mappings: List[DataMapping] = field(default_factory=list)
    filters: Dict[str, Any] = field(default_factory=dict)
    last_sync: Optional[datetime] = None
    sync_key_field: Optional[str] = None

@dataclass
class Integration:
    """é›†æˆé…ç½®"""
    id: str
    name: str
    integration_type: IntegrationType
    description: str = ""
    base_url: str = ""
    auth_config: Optional[AuthConfig] = None
    endpoints: Dict[str, EndpointConfig] = field(default_factory=dict)
    sync_config: Optional[SyncConfig] = None
    status: IntegrationStatus = IntegrationStatus.INACTIVE
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    
    def __post_init__(self):
        if isinstance(self.integration_type, str):
            self.integration_type = IntegrationType(self.integration_type)
        if isinstance(self.status, str):
            self.status = IntegrationStatus(self.status)

@dataclass
class IntegrationResult:
    """é›†æˆæ‰§è¡Œç»“æœ"""
    integration_id: str
    endpoint: str
    success: bool
    status_code: Optional[int] = None
    response_data: Any = None
    error_message: Optional[str] = None
    execution_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class SyncResult:
    """åŒæ­¥ç»“æœ"""
    integration_id: str
    direction: SyncDirection
    success: bool
    records_processed: int = 0
    records_success: int = 0
    records_failed: int = 0
    error_message: Optional[str] = None
    execution_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)

class IntegrationManager:
    """é›†æˆç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = None):
        """åˆå§‹åŒ–é›†æˆç®¡ç†å™¨"""
        if project_root is None:
            self.project_root = Path(__file__).parent.parent.parent
        else:
            self.project_root = Path(project_root)
        
        # é›†æˆç®¡ç†ç›®å½•
        self.integration_dir = self.project_root / "integrations"
        self.config_dir = self.integration_dir / "config"
        self.data_dir = self.integration_dir / "data"
        self.logs_dir = self.integration_dir / "logs"
        self.cache_dir = self.integration_dir / "cache"
        
        # åˆ›å»ºç›®å½•
        for directory in [self.integration_dir, self.config_dir, self.data_dir, 
                         self.logs_dir, self.cache_dir]:
            directory.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ–‡ä»¶
        self.config_file = self.config_dir / "integration_config.json"
        self.integrations_file = self.config_dir / "integrations.json"
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger('yds_lab.integration_manager')
        self._setup_logging()
        
        # åŠ è½½é…ç½®
        self._load_config()
        
        # é›†æˆå®ä¾‹
        self.integrations: Dict[str, Integration] = {}
        self._load_integrations()
        
        # ä¼šè¯ç®¡ç†
        self.session = None
        if REQUESTS_AVAILABLE:
            self.session = requests.Session()
        
        # å¼‚æ­¥ä¼šè¯
        self.async_session = None
        
        # çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(max_workers=10)
        
        # ç¼“å­˜
        self.cache = {}
        
        # åŠ å¯†å¯†é’¥
        self.encryption_key = self._get_or_create_encryption_key()
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = self.logs_dir / f"integration_{datetime.now().strftime('%Y%m%d')}.log"
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(formatter)
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(logging.WARNING)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        self.logger.setLevel(logging.INFO)
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
            except Exception as e:
                self.logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
                self.config = {}
        else:
            self.config = {
                'default_timeout': 30,
                'default_retry_count': 3,
                'default_retry_delay': 1.0,
                'max_concurrent_requests': 10,
                'cache_ttl': 3600,
                'sync_batch_size': 100,
                'webhook_secret': None,
                'rate_limit': {
                    'enabled': True,
                    'requests_per_minute': 60,
                    'burst_limit': 10
                },
                'security': {
                    'encrypt_credentials': True,
                    'validate_ssl': True,
                    'allowed_hosts': []
                }
            }
            self._save_config()
    
    def _save_config(self):
        """ä¿å­˜é…ç½®"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def _load_integrations(self):
        """åŠ è½½é›†æˆé…ç½®"""
        if self.integrations_file.exists():
            try:
                with open(self.integrations_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                for integration_data in data.get('integrations', []):
                    # è§£å¯†å‡­æ®
                    if integration_data.get('auth_config', {}).get('credentials'):
                        integration_data['auth_config']['credentials'] = self._decrypt_credentials(
                            integration_data['auth_config']['credentials']
                        )
                    
                    # è½¬æ¢æ—¥æœŸæ—¶é—´
                    for field in ['created_at', 'updated_at']:
                        if field in integration_data:
                            integration_data[field] = datetime.fromisoformat(integration_data[field])
                    
                    # è½¬æ¢åŒæ­¥é…ç½®ä¸­çš„æ—¥æœŸæ—¶é—´
                    if integration_data.get('sync_config', {}).get('last_sync'):
                        integration_data['sync_config']['last_sync'] = datetime.fromisoformat(
                            integration_data['sync_config']['last_sync']
                        )
                    
                    # åˆ›å»ºé›†æˆå®ä¾‹
                    integration = Integration(**integration_data)
                    self.integrations[integration.id] = integration
                
                self.logger.info(f"å·²åŠ è½½ {len(self.integrations)} ä¸ªé›†æˆé…ç½®")
            
            except Exception as e:
                self.logger.error(f"åŠ è½½é›†æˆé…ç½®å¤±è´¥: {e}")
    
    def _save_integrations(self):
        """ä¿å­˜é›†æˆé…ç½®"""
        try:
            integrations_data = []
            
            for integration in self.integrations.values():
                integration_dict = asdict(integration)
                
                # åŠ å¯†å‡­æ®
                if integration_dict.get('auth_config', {}).get('credentials'):
                    integration_dict['auth_config']['credentials'] = self._encrypt_credentials(
                        integration_dict['auth_config']['credentials']
                    )
                
                # è½¬æ¢æšä¸¾ä¸ºå­—ç¬¦ä¸²
                integration_dict['integration_type'] = integration.integration_type.value
                integration_dict['status'] = integration.status.value
                
                if integration.auth_config and integration.auth_config.auth_type:
                    integration_dict['auth_config']['auth_type'] = integration.auth_config.auth_type.value
                
                if integration.sync_config and integration.sync_config.direction:
                    integration_dict['sync_config']['direction'] = integration.sync_config.direction.value
                
                # è½¬æ¢æ—¥æœŸæ—¶é—´ä¸ºå­—ç¬¦ä¸²
                for field in ['created_at', 'updated_at']:
                    if field in integration_dict:
                        integration_dict[field] = integration_dict[field].isoformat()
                
                if integration_dict.get('sync_config', {}).get('last_sync'):
                    integration_dict['sync_config']['last_sync'] = integration_dict['sync_config']['last_sync'].isoformat()
                
                integrations_data.append(integration_dict)
            
            data = {'integrations': integrations_data}
            
            with open(self.integrations_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"å·²ä¿å­˜ {len(integrations_data)} ä¸ªé›†æˆé…ç½®")
        
        except Exception as e:
            self.logger.error(f"ä¿å­˜é›†æˆé…ç½®å¤±è´¥: {e}")
    
    def _get_or_create_encryption_key(self) -> bytes:
        """è·å–æˆ–åˆ›å»ºåŠ å¯†å¯†é’¥"""
        key_file = self.config_dir / ".encryption_key"
        
        if key_file.exists() and CRYPTO_AVAILABLE:
            try:
                return key_file.read_bytes()
            except Exception:
                pass
        
        if CRYPTO_AVAILABLE:
            key = Fernet.generate_key()
            try:
                key_file.write_bytes(key)
                key_file.chmod(0o600)  # ä»…æ‰€æœ‰è€…å¯è¯»å†™
                return key
            except Exception:
                pass
        
        # å¦‚æœæ— æ³•ä½¿ç”¨åŠ å¯†ï¼Œè¿”å›å›ºå®šå¯†é’¥ï¼ˆä¸å®‰å…¨ï¼‰
        return b"insecure_fallback_key_32_bytes_"
    
    def _encrypt_credentials(self, credentials: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ å¯†å‡­æ®"""
        if not self.config.get('security', {}).get('encrypt_credentials', True):
            return credentials
        
        if not CRYPTO_AVAILABLE:
            self.logger.warning("åŠ å¯†åº“ä¸å¯ç”¨ï¼Œå‡­æ®å°†ä»¥æ˜æ–‡å­˜å‚¨")
            return credentials
        
        try:
            fernet = Fernet(self.encryption_key)
            encrypted_credentials = {}
            
            for key, value in credentials.items():
                if isinstance(value, str) and value:
                    encrypted_value = fernet.encrypt(value.encode()).decode()
                    encrypted_credentials[key] = f"encrypted:{encrypted_value}"
                else:
                    encrypted_credentials[key] = value
            
            return encrypted_credentials
        
        except Exception as e:
            self.logger.error(f"åŠ å¯†å‡­æ®å¤±è´¥: {e}")
            return credentials
    
    def _decrypt_credentials(self, credentials: Dict[str, Any]) -> Dict[str, Any]:
        """è§£å¯†å‡­æ®"""
        if not CRYPTO_AVAILABLE:
            return credentials
        
        try:
            fernet = Fernet(self.encryption_key)
            decrypted_credentials = {}
            
            for key, value in credentials.items():
                if isinstance(value, str) and value.startswith("encrypted:"):
                    encrypted_value = value[10:]  # ç§»é™¤"encrypted:"å‰ç¼€
                    decrypted_value = fernet.decrypt(encrypted_value.encode()).decode()
                    decrypted_credentials[key] = decrypted_value
                else:
                    decrypted_credentials[key] = value
            
            return decrypted_credentials
        
        except Exception as e:
            self.logger.error(f"è§£å¯†å‡­æ®å¤±è´¥: {e}")
            return credentials
    
    def add_integration(self, integration: Integration) -> bool:
        """æ·»åŠ é›†æˆ"""
        try:
            integration.updated_at = datetime.now()
            self.integrations[integration.id] = integration
            self._save_integrations()
            
            self.logger.info(f"å·²æ·»åŠ é›†æˆ: {integration.name} ({integration.id})")
            return True
        
        except Exception as e:
            self.logger.error(f"æ·»åŠ é›†æˆå¤±è´¥: {e}")
            return False
    
    def remove_integration(self, integration_id: str) -> bool:
        """ç§»é™¤é›†æˆ"""
        try:
            if integration_id in self.integrations:
                integration = self.integrations[integration_id]
                del self.integrations[integration_id]
                self._save_integrations()
                
                self.logger.info(f"å·²ç§»é™¤é›†æˆ: {integration.name} ({integration_id})")
                return True
            else:
                self.logger.warning(f"é›†æˆä¸å­˜åœ¨: {integration_id}")
                return False
        
        except Exception as e:
            self.logger.error(f"ç§»é™¤é›†æˆå¤±è´¥: {e}")
            return False
    
    def update_integration(self, integration_id: str, **kwargs) -> bool:
        """æ›´æ–°é›†æˆ"""
        try:
            if integration_id not in self.integrations:
                self.logger.error(f"é›†æˆä¸å­˜åœ¨: {integration_id}")
                return False
            
            integration = self.integrations[integration_id]
            
            for key, value in kwargs.items():
                if hasattr(integration, key):
                    setattr(integration, key, value)
            
            integration.updated_at = datetime.now()
            self._save_integrations()
            
            self.logger.info(f"å·²æ›´æ–°é›†æˆ: {integration.name} ({integration_id})")
            return True
        
        except Exception as e:
            self.logger.error(f"æ›´æ–°é›†æˆå¤±è´¥: {e}")
            return False
    
    def get_integration(self, integration_id: str) -> Optional[Integration]:
        """è·å–é›†æˆ"""
        return self.integrations.get(integration_id)
    
    def list_integrations(self, status: IntegrationStatus = None, 
                         integration_type: IntegrationType = None) -> List[Integration]:
        """åˆ—å‡ºé›†æˆ"""
        integrations = list(self.integrations.values())
        
        if status:
            integrations = [i for i in integrations if i.status == status]
        
        if integration_type:
            integrations = [i for i in integrations if i.integration_type == integration_type]
        
        return integrations
    
    def test_integration(self, integration_id: str, endpoint: str = None) -> IntegrationResult:
        """æµ‹è¯•é›†æˆ"""
        integration = self.get_integration(integration_id)
        if not integration:
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint or "unknown",
                success=False,
                error_message="é›†æˆä¸å­˜åœ¨"
            )
        
        start_time = time.time()
        
        try:
            # é€‰æ‹©æµ‹è¯•ç«¯ç‚¹
            if endpoint and endpoint in integration.endpoints:
                endpoint_config = integration.endpoints[endpoint]
            elif integration.endpoints:
                endpoint_name = list(integration.endpoints.keys())[0]
                endpoint_config = integration.endpoints[endpoint_name]
                endpoint = endpoint_name
            else:
                # åˆ›å»ºé»˜è®¤æµ‹è¯•ç«¯ç‚¹
                endpoint_config = EndpointConfig(
                    url=integration.base_url,
                    method="GET"
                )
                endpoint = "default"
            
            # æ‰§è¡Œè¯·æ±‚
            result = self._execute_request(integration, endpoint_config)
            
            execution_time = time.time() - start_time
            
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint,
                success=result.get('success', False),
                status_code=result.get('status_code'),
                response_data=result.get('data'),
                error_message=result.get('error'),
                execution_time=execution_time
            )
        
        except Exception as e:
            execution_time = time.time() - start_time
            
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint or "unknown",
                success=False,
                error_message=str(e),
                execution_time=execution_time
            )
    
    def _execute_request(self, integration: Integration, 
                        endpoint_config: EndpointConfig) -> Dict[str, Any]:
        """æ‰§è¡ŒHTTPè¯·æ±‚"""
        if not REQUESTS_AVAILABLE:
            return {
                'success': False,
                'error': 'requestsåº“ä¸å¯ç”¨'
            }
        
        try:
            # æ„å»ºURL
            if endpoint_config.url.startswith('http'):
                url = endpoint_config.url
            else:
                url = urljoin(integration.base_url, endpoint_config.url)
            
            # å‡†å¤‡è¯·æ±‚å‚æ•°
            headers = dict(endpoint_config.headers)
            params = dict(endpoint_config.params)
            
            # æ·»åŠ è®¤è¯
            if integration.auth_config:
                self._add_authentication(headers, params, integration.auth_config)
            
            # æ‰§è¡Œè¯·æ±‚
            response = self.session.request(
                method=endpoint_config.method,
                url=url,
                headers=headers,
                params=params,
                json=endpoint_config.data,
                timeout=endpoint_config.timeout
            )
            
            # å¤„ç†å“åº”
            try:
                response_data = response.json()
            except:
                response_data = response.text
            
            return {
                'success': response.status_code < 400,
                'status_code': response.status_code,
                'data': response_data,
                'headers': dict(response.headers)
            }
        
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _add_authentication(self, headers: Dict[str, str], params: Dict[str, str], 
                          auth_config: AuthConfig):
        """æ·»åŠ è®¤è¯ä¿¡æ¯"""
        if auth_config.auth_type == AuthType.API_KEY:
            api_key = auth_config.credentials.get('api_key')
            key_location = auth_config.credentials.get('key_location', 'header')
            key_name = auth_config.credentials.get('key_name', 'X-API-Key')
            
            if api_key:
                if key_location == 'header':
                    headers[key_name] = api_key
                elif key_location == 'query':
                    params[key_name] = api_key
        
        elif auth_config.auth_type == AuthType.BEARER_TOKEN:
            token = auth_config.credentials.get('token')
            if token:
                headers['Authorization'] = f'Bearer {token}'
        
        elif auth_config.auth_type == AuthType.BASIC_AUTH:
            username = auth_config.credentials.get('username')
            password = auth_config.credentials.get('password')
            if username and password:
                credentials = base64.b64encode(f"{username}:{password}".encode()).decode()
                headers['Authorization'] = f'Basic {credentials}'
        
        elif auth_config.auth_type == AuthType.JWT:
            token = auth_config.credentials.get('token')
            if token:
                headers['Authorization'] = f'Bearer {token}'
        
        # æ·»åŠ è‡ªå®šä¹‰å¤´éƒ¨å’Œå‚æ•°
        headers.update(auth_config.headers)
        params.update(auth_config.params)
    
    def call_endpoint(self, integration_id: str, endpoint: str, 
                     data: Dict[str, Any] = None, **kwargs) -> IntegrationResult:
        """è°ƒç”¨é›†æˆç«¯ç‚¹"""
        integration = self.get_integration(integration_id)
        if not integration:
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint,
                success=False,
                error_message="é›†æˆä¸å­˜åœ¨"
            )
        
        if endpoint not in integration.endpoints:
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint,
                success=False,
                error_message="ç«¯ç‚¹ä¸å­˜åœ¨"
            )
        
        start_time = time.time()
        
        try:
            endpoint_config = integration.endpoints[endpoint]
            
            # è¦†ç›–é…ç½®
            if data is not None:
                endpoint_config.data = data
            
            for key, value in kwargs.items():
                if hasattr(endpoint_config, key):
                    setattr(endpoint_config, key, value)
            
            # æ‰§è¡Œè¯·æ±‚
            result = self._execute_request(integration, endpoint_config)
            
            execution_time = time.time() - start_time
            
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint,
                success=result.get('success', False),
                status_code=result.get('status_code'),
                response_data=result.get('data'),
                error_message=result.get('error'),
                execution_time=execution_time
            )
        
        except Exception as e:
            execution_time = time.time() - start_time
            
            return IntegrationResult(
                integration_id=integration_id,
                endpoint=endpoint,
                success=False,
                error_message=str(e),
                execution_time=execution_time
            )
    
    def sync_data(self, integration_id: str, direction: SyncDirection = None) -> SyncResult:
        """åŒæ­¥æ•°æ®"""
        integration = self.get_integration(integration_id)
        if not integration:
            return SyncResult(
                integration_id=integration_id,
                direction=direction or SyncDirection.PULL,
                success=False,
                error_message="é›†æˆä¸å­˜åœ¨"
            )
        
        if not integration.sync_config:
            return SyncResult(
                integration_id=integration_id,
                direction=direction or SyncDirection.PULL,
                success=False,
                error_message="æœªé…ç½®åŒæ­¥"
            )
        
        sync_direction = direction or integration.sync_config.direction
        start_time = time.time()
        
        try:
            if sync_direction == SyncDirection.PULL:
                result = self._sync_pull_data(integration)
            elif sync_direction == SyncDirection.PUSH:
                result = self._sync_push_data(integration)
            elif sync_direction == SyncDirection.BIDIRECTIONAL:
                pull_result = self._sync_pull_data(integration)
                push_result = self._sync_push_data(integration)
                
                result = SyncResult(
                    integration_id=integration_id,
                    direction=sync_direction,
                    success=pull_result.success and push_result.success,
                    records_processed=pull_result.records_processed + push_result.records_processed,
                    records_success=pull_result.records_success + push_result.records_success,
                    records_failed=pull_result.records_failed + push_result.records_failed,
                    error_message=pull_result.error_message or push_result.error_message,
                    execution_time=time.time() - start_time
                )
            else:
                result = SyncResult(
                    integration_id=integration_id,
                    direction=sync_direction,
                    success=False,
                    error_message="ä¸æ”¯æŒçš„åŒæ­¥æ–¹å‘"
                )
            
            # æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
            if result.success:
                integration.sync_config.last_sync = datetime.now()
                self._save_integrations()
            
            return result
        
        except Exception as e:
            execution_time = time.time() - start_time
            
            return SyncResult(
                integration_id=integration_id,
                direction=sync_direction,
                success=False,
                error_message=str(e),
                execution_time=execution_time
            )
    
    def _sync_pull_data(self, integration: Integration) -> SyncResult:
        """æ‹‰å–æ•°æ®åŒæ­¥"""
        # è¿™é‡Œåº”è¯¥å®ç°å…·ä½“çš„æ•°æ®æ‹‰å–é€»è¾‘
        # æ ¹æ®é›†æˆç±»å‹å’Œé…ç½®ä»å¤–éƒ¨ç³»ç»Ÿæ‹‰å–æ•°æ®
        
        records_processed = 0
        records_success = 0
        records_failed = 0
        
        try:
            # ç¤ºä¾‹ï¼šä»REST APIæ‹‰å–æ•°æ®
            if integration.integration_type == IntegrationType.REST_API:
                if 'list' in integration.endpoints:
                    endpoint_config = integration.endpoints['list']
                    result = self._execute_request(integration, endpoint_config)
                    
                    if result.get('success'):
                        data = result.get('data', [])
                        if isinstance(data, list):
                            records_processed = len(data)
                            records_success = records_processed
                            
                            # ä¿å­˜æ•°æ®åˆ°æœ¬åœ°
                            self._save_sync_data(integration.id, 'pull', data)
                        else:
                            records_processed = 1
                            records_success = 1
                            self._save_sync_data(integration.id, 'pull', [data])
            
            return SyncResult(
                integration_id=integration.id,
                direction=SyncDirection.PULL,
                success=records_failed == 0,
                records_processed=records_processed,
                records_success=records_success,
                records_failed=records_failed
            )
        
        except Exception as e:
            return SyncResult(
                integration_id=integration.id,
                direction=SyncDirection.PULL,
                success=False,
                error_message=str(e)
            )
    
    def _sync_push_data(self, integration: Integration) -> SyncResult:
        """æ¨é€æ•°æ®åŒæ­¥"""
        # è¿™é‡Œåº”è¯¥å®ç°å…·ä½“çš„æ•°æ®æ¨é€é€»è¾‘
        # æ ¹æ®é›†æˆç±»å‹å’Œé…ç½®å‘å¤–éƒ¨ç³»ç»Ÿæ¨é€æ•°æ®
        
        records_processed = 0
        records_success = 0
        records_failed = 0
        
        try:
            # è·å–å¾…æ¨é€çš„æ•°æ®
            local_data = self._get_local_sync_data(integration.id, 'push')
            
            if not local_data:
                return SyncResult(
                    integration_id=integration.id,
                    direction=SyncDirection.PUSH,
                    success=True,
                    records_processed=0,
                    records_success=0,
                    records_failed=0
                )
            
            # ç¤ºä¾‹ï¼šæ¨é€æ•°æ®åˆ°REST API
            if integration.integration_type == IntegrationType.REST_API:
                if 'create' in integration.endpoints:
                    endpoint_config = integration.endpoints['create']
                    
                    for record in local_data:
                        records_processed += 1
                        
                        # åº”ç”¨æ•°æ®æ˜ å°„
                        mapped_data = self._apply_data_mapping(
                            record, integration.sync_config.data_mappings
                        )
                        
                        endpoint_config.data = mapped_data
                        result = self._execute_request(integration, endpoint_config)
                        
                        if result.get('success'):
                            records_success += 1
                        else:
                            records_failed += 1
            
            return SyncResult(
                integration_id=integration.id,
                direction=SyncDirection.PUSH,
                success=records_failed == 0,
                records_processed=records_processed,
                records_success=records_success,
                records_failed=records_failed
            )
        
        except Exception as e:
            return SyncResult(
                integration_id=integration.id,
                direction=SyncDirection.PUSH,
                success=False,
                error_message=str(e)
            )
    
    def _apply_data_mapping(self, data: Dict[str, Any], 
                           mappings: List[DataMapping]) -> Dict[str, Any]:
        """åº”ç”¨æ•°æ®æ˜ å°„"""
        mapped_data = {}
        
        for mapping in mappings:
            source_value = data.get(mapping.source_field, mapping.default_value)
            
            # åº”ç”¨è½¬æ¢å‡½æ•°
            if mapping.transform_function and source_value is not None:
                try:
                    # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è½¬æ¢é€»è¾‘
                    if mapping.transform_function == 'upper':
                        source_value = str(source_value).upper()
                    elif mapping.transform_function == 'lower':
                        source_value = str(source_value).lower()
                    elif mapping.transform_function == 'strip':
                        source_value = str(source_value).strip()
                except Exception as e:
                    self.logger.warning(f"æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            
            # æ£€æŸ¥å¿…å¡«å­—æ®µ
            if mapping.required and source_value is None:
                raise ValueError(f"å¿…å¡«å­—æ®µç¼ºå¤±: {mapping.source_field}")
            
            if source_value is not None:
                mapped_data[mapping.target_field] = source_value
        
        return mapped_data
    
    def _save_sync_data(self, integration_id: str, direction: str, data: List[Dict[str, Any]]):
        """ä¿å­˜åŒæ­¥æ•°æ®"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{integration_id}_{direction}_{timestamp}.json"
            filepath = self.data_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"å·²ä¿å­˜åŒæ­¥æ•°æ®: {filepath}")
        
        except Exception as e:
            self.logger.error(f"ä¿å­˜åŒæ­¥æ•°æ®å¤±è´¥: {e}")
    
    def _get_local_sync_data(self, integration_id: str, direction: str) -> List[Dict[str, Any]]:
        """è·å–æœ¬åœ°åŒæ­¥æ•°æ®"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
            pattern = f"{integration_id}_{direction}_*.json"
            files = list(self.data_dir.glob(pattern))
            
            if not files:
                return []
            
            # æŒ‰æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°æ–‡ä»¶
            latest_file = sorted(files, key=lambda f: f.stat().st_mtime, reverse=True)[0]
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        except Exception as e:
            self.logger.error(f"è·å–æœ¬åœ°åŒæ­¥æ•°æ®å¤±è´¥: {e}")
            return []
    
    def get_integration_status(self, integration_id: str) -> Dict[str, Any]:
        """è·å–é›†æˆçŠ¶æ€"""
        integration = self.get_integration(integration_id)
        if not integration:
            return {'error': 'é›†æˆä¸å­˜åœ¨'}
        
        # æµ‹è¯•è¿æ¥
        test_result = self.test_integration(integration_id)
        
        # è·å–æœ€è¿‘çš„åŒæ­¥ç»“æœ
        last_sync = None
        if integration.sync_config and integration.sync_config.last_sync:
            last_sync = integration.sync_config.last_sync.isoformat()
        
        return {
            'id': integration.id,
            'name': integration.name,
            'type': integration.integration_type.value,
            'status': integration.status.value,
            'base_url': integration.base_url,
            'endpoints_count': len(integration.endpoints),
            'has_auth': integration.auth_config is not None,
            'has_sync': integration.sync_config is not None,
            'last_sync': last_sync,
            'connection_test': {
                'success': test_result.success,
                'status_code': test_result.status_code,
                'response_time': test_result.execution_time,
                'error': test_result.error_message
            },
            'created_at': integration.created_at.isoformat(),
            'updated_at': integration.updated_at.isoformat()
        }
    
    def generate_integration_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆé›†æˆæŠ¥å‘Š"""
        report = {
            'summary': {
                'total_integrations': len(self.integrations),
                'active_integrations': len([i for i in self.integrations.values() 
                                          if i.status == IntegrationStatus.ACTIVE]),
                'inactive_integrations': len([i for i in self.integrations.values() 
                                            if i.status == IntegrationStatus.INACTIVE]),
                'error_integrations': len([i for i in self.integrations.values() 
                                         if i.status == IntegrationStatus.ERROR])
            },
            'by_type': {},
            'integrations': [],
            'generated_at': datetime.now().isoformat()
        }
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        for integration in self.integrations.values():
            type_name = integration.integration_type.value
            if type_name not in report['by_type']:
                report['by_type'][type_name] = 0
            report['by_type'][type_name] += 1
        
        # é›†æˆè¯¦æƒ…
        for integration in self.integrations.values():
            status_info = self.get_integration_status(integration.id)
            report['integrations'].append(status_info)
        
        return report
    
    def cleanup_old_data(self, days: int = 30):
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            cleaned_count = 0
            
            # æ¸…ç†æ•°æ®æ–‡ä»¶
            for data_file in self.data_dir.glob("*.json"):
                if data_file.stat().st_mtime < cutoff_date.timestamp():
                    data_file.unlink()
                    cleaned_count += 1
            
            # æ¸…ç†æ—¥å¿—æ–‡ä»¶
            for log_file in self.logs_dir.glob("*.log"):
                if log_file.stat().st_mtime < cutoff_date.timestamp():
                    log_file.unlink()
                    cleaned_count += 1
            
            self.logger.info(f"å·²æ¸…ç† {cleaned_count} ä¸ªæ—§æ–‡ä»¶")
            return cleaned_count
        
        except Exception as e:
            self.logger.error(f"æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
            return 0

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='YDS-Lab é›†æˆç®¡ç†å·¥å…·')
    parser.add_argument('--project-root', help='æŒ‡å®šé¡¹ç›®æ ¹ç›®å½•è·¯å¾„')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # åˆ—å‡ºé›†æˆ
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºé›†æˆ')
    list_parser.add_argument('--status', choices=['active', 'inactive', 'error', 'testing', 'maintenance'], 
                           help='æŒ‰çŠ¶æ€è¿‡æ»¤')
    list_parser.add_argument('--type', help='æŒ‰ç±»å‹è¿‡æ»¤')
    
    # æµ‹è¯•é›†æˆ
    test_parser = subparsers.add_parser('test', help='æµ‹è¯•é›†æˆ')
    test_parser.add_argument('integration_id', help='é›†æˆID')
    test_parser.add_argument('--endpoint', help='æŒ‡å®šç«¯ç‚¹')
    
    # è°ƒç”¨ç«¯ç‚¹
    call_parser = subparsers.add_parser('call', help='è°ƒç”¨é›†æˆç«¯ç‚¹')
    call_parser.add_argument('integration_id', help='é›†æˆID')
    call_parser.add_argument('endpoint', help='ç«¯ç‚¹åç§°')
    call_parser.add_argument('--data', help='è¯·æ±‚æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰')
    
    # åŒæ­¥æ•°æ®
    sync_parser = subparsers.add_parser('sync', help='åŒæ­¥æ•°æ®')
    sync_parser.add_argument('integration_id', help='é›†æˆID')
    sync_parser.add_argument('--direction', choices=['pull', 'push', 'bidirectional'], 
                           help='åŒæ­¥æ–¹å‘')
    
    # çŠ¶æ€æ£€æŸ¥
    status_parser = subparsers.add_parser('status', help='æ£€æŸ¥é›†æˆçŠ¶æ€')
    status_parser.add_argument('integration_id', help='é›†æˆID')
    
    # ç”ŸæˆæŠ¥å‘Š
    report_parser = subparsers.add_parser('report', help='ç”Ÿæˆé›†æˆæŠ¥å‘Š')
    report_parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    # æ¸…ç†æ•°æ®
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§æ•°æ®')
    cleanup_parser.add_argument('--days', type=int, default=30, help='ä¿ç•™å¤©æ•°')
    
    args = parser.parse_args()
    
    manager = IntegrationManager(args.project_root)
    
    if args.command == 'list':
        status_filter = IntegrationStatus(args.status) if args.status else None
        type_filter = IntegrationType(args.type) if args.type else None
        
        integrations = manager.list_integrations(status_filter, type_filter)
        
        print(f"ğŸ“‹ é›†æˆåˆ—è¡¨ (å…±{len(integrations)}ä¸ª):")
        print("="*60)
        
        for integration in integrations:
            print(f"ID: {integration.id}")
            print(f"åç§°: {integration.name}")
            print(f"ç±»å‹: {integration.integration_type.value}")
            print(f"çŠ¶æ€: {integration.status.value}")
            print(f"åŸºç¡€URL: {integration.base_url}")
            print(f"ç«¯ç‚¹æ•°é‡: {len(integration.endpoints)}")
            print(f"åˆ›å»ºæ—¶é—´: {integration.created_at}")
            print("-" * 60)
    
    elif args.command == 'test':
        result = manager.test_integration(args.integration_id, args.endpoint)
        
        print(f"ğŸ§ª é›†æˆæµ‹è¯•ç»“æœ:")
        print(f"é›†æˆID: {result.integration_id}")
        print(f"ç«¯ç‚¹: {result.endpoint}")
        print(f"æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
        if result.status_code:
            print(f"çŠ¶æ€ç : {result.status_code}")
        print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        if result.error_message:
            print(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
        if result.response_data:
            print(f"å“åº”æ•°æ®: {json.dumps(result.response_data, indent=2, ensure_ascii=False)}")
    
    elif args.command == 'call':
        data = None
        if args.data:
            try:
                data = json.loads(args.data)
            except json.JSONDecodeError:
                print("âŒ æ— æ•ˆçš„JSONæ•°æ®æ ¼å¼")
                return
        
        result = manager.call_endpoint(args.integration_id, args.endpoint, data)
        
        print(f"ğŸ“ ç«¯ç‚¹è°ƒç”¨ç»“æœ:")
        print(f"é›†æˆID: {result.integration_id}")
        print(f"ç«¯ç‚¹: {result.endpoint}")
        print(f"æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
        if result.status_code:
            print(f"çŠ¶æ€ç : {result.status_code}")
        print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        if result.error_message:
            print(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
        if result.response_data:
            print(f"å“åº”æ•°æ®: {json.dumps(result.response_data, indent=2, ensure_ascii=False)}")
    
    elif args.command == 'sync':
        direction = SyncDirection(args.direction) if args.direction else None
        result = manager.sync_data(args.integration_id, direction)
        
        print(f"ğŸ”„ æ•°æ®åŒæ­¥ç»“æœ:")
        print(f"é›†æˆID: {result.integration_id}")
        print(f"æ–¹å‘: {result.direction.value}")
        print(f"æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
        print(f"å¤„ç†è®°å½•: {result.records_processed}")
        print(f"æˆåŠŸè®°å½•: {result.records_success}")
        print(f"å¤±è´¥è®°å½•: {result.records_failed}")
        print(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        if result.error_message:
            print(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
    
    elif args.command == 'status':
        status = manager.get_integration_status(args.integration_id)
        
        if 'error' in status:
            print(f"âŒ {status['error']}")
            return
        
        print(f"ğŸ“Š é›†æˆçŠ¶æ€:")
        print(f"ID: {status['id']}")
        print(f"åç§°: {status['name']}")
        print(f"ç±»å‹: {status['type']}")
        print(f"çŠ¶æ€: {status['status']}")
        print(f"åŸºç¡€URL: {status['base_url']}")
        print(f"ç«¯ç‚¹æ•°é‡: {status['endpoints_count']}")
        print(f"è®¤è¯é…ç½®: {'æ˜¯' if status['has_auth'] else 'å¦'}")
        print(f"åŒæ­¥é…ç½®: {'æ˜¯' if status['has_sync'] else 'å¦'}")
        print(f"æœ€ååŒæ­¥: {status['last_sync'] or 'ä»æœªåŒæ­¥'}")
        
        conn_test = status['connection_test']
        print(f"è¿æ¥æµ‹è¯•: {'âœ…' if conn_test['success'] else 'âŒ'}")
        if conn_test['status_code']:
            print(f"  çŠ¶æ€ç : {conn_test['status_code']}")
        print(f"  å“åº”æ—¶é—´: {conn_test['response_time']:.2f}ç§’")
        if conn_test['error']:
            print(f"  é”™è¯¯: {conn_test['error']}")
    
    elif args.command == 'report':
        report = manager.generate_integration_report()
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print("ğŸ“Š é›†æˆæŠ¥å‘Š:")
            print("="*40)
            
            summary = report['summary']
            print(f"æ€»é›†æˆæ•°: {summary['total_integrations']}")
            print(f"æ´»è·ƒé›†æˆ: {summary['active_integrations']}")
            print(f"éæ´»è·ƒé›†æˆ: {summary['inactive_integrations']}")
            print(f"é”™è¯¯é›†æˆ: {summary['error_integrations']}")
            
            print(f"\næŒ‰ç±»å‹ç»Ÿè®¡:")
            for type_name, count in report['by_type'].items():
                print(f"  {type_name}: {count}")
            
            print(f"\nç”Ÿæˆæ—¶é—´: {report['generated_at']}")
    
    elif args.command == 'cleanup':
        cleaned_count = manager.cleanup_old_data(args.days)
        print(f"ğŸ§¹ å·²æ¸…ç† {cleaned_count} ä¸ªæ—§æ–‡ä»¶ (ä¿ç•™{args.days}å¤©å†…çš„æ•°æ®)")
    
    else:
        # é»˜è®¤æ˜¾ç¤ºçŠ¶æ€
        integrations = manager.list_integrations()
        
        print("ğŸ”— é›†æˆç®¡ç†å™¨")
        print("="*30)
        print(f"é¡¹ç›®è·¯å¾„: {manager.project_root}")
        print(f"é›†æˆç›®å½•: {manager.integration_dir}")
        print(f"æ€»é›†æˆæ•°: {len(integrations)}")
        
        if integrations:
            active_count = len([i for i in integrations if i.status == IntegrationStatus.ACTIVE])
            print(f"æ´»è·ƒé›†æˆ: {active_count}")
            
            print(f"\nğŸ“‹ é›†æˆåˆ—è¡¨:")
            for integration in integrations[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"  {integration.name} ({integration.integration_type.value}) - {integration.status.value}")
            
            if len(integrations) > 5:
                print(f"  ... è¿˜æœ‰ {len(integrations) - 5} ä¸ªé›†æˆ")

if __name__ == "__main__":
    main()