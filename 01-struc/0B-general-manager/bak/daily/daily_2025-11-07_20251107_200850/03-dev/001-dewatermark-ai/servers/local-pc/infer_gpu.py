# infer_gpu.py
# æ±Ÿé—¨å°å¼æœº GPU åŠ é€Ÿæ¨ç†æœåŠ¡ï¼ˆCUDA æ¨¡å¼ï¼‰
# è·¯å¾„: S:\YDS-Lab\projects\dewatermark-ai\servers\local-pc\

import os
import sys
import shutil
import torch
import torchvision.transforms as T
from PIL import Image
from flask import Flask, request, jsonify

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ç®€åŒ–æ—¥å¿—å‡½æ•°ï¼Œé¿å…ä¾èµ–å¤–éƒ¨æ¨¡å—
def log_to_general_office(message, category="info"):
    import datetime
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{category.upper()}] {message}")

app = Flask(__name__)

# æ¨¡å‹è·¯å¾„ï¼ˆè½»é‡çº§ LaMa-256pxï¼‰
LAMA_256_MODEL_PATH = os.path.join(project_root, "projects", "dewatermark-ai", "models", "lama_256", "lama_256.pth")
OUTPUT_DIR = os.path.join(project_root, "projects", "dewatermark-ai", "output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…åŠ è½½ä¸€æ¬¡ï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ç®€åŒ–æ¨¡å‹åŠ è½½ï¼ˆå®é™…åº”æ›¿æ¢ä¸ºå®Œæ•´æ¨ç†é€»è¾‘ï¼‰
def load_lama_256():
    # æ­¤å¤„åº”åŠ è½½å®é™…çš„ LaMa æ¨¡å‹
    log_to_general_office("æ±Ÿé—¨æœºåŠ è½½ LaMa-256px æ¨¡å‹", "operations")
    return lambda x: x  # å ä½ç¬¦

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå¯é€‰ï¼‰
LAMA_256_MODEL_PATH = os.path.join(project_root, "projects", "dewatermark-ai", "models", "lama_256", "lama_256.pth")
if os.path.exists(LAMA_256_MODEL_PATH):
    log_to_general_office(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {LAMA_256_MODEL_PATH}", "info")
else:
    log_to_general_office(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨å ä½ç¬¦: {LAMA_256_MODEL_PATH}", "warning")

model = load_lama_256()

@app.route("/", methods=["GET"])
def index():
    """æœåŠ¡çŠ¶æ€é¡µé¢"""
    gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "æ— GPU"
    device_info = "CUDA" if torch.cuda.is_available() else "CPU"
    
    return f"""
    <html>
    <head>
        <title>æ±Ÿé—¨æœº GPU æ¨ç†æœåŠ¡</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
            .container {{ background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            .status {{ color: #28a745; font-weight: bold; }}
            .info {{ margin: 10px 0; }}
            .endpoint {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-left: 4px solid #007bff; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš€ æ±Ÿé—¨æœº GPU æ¨ç†æœåŠ¡</h1>
            <div class="status">âœ… æœåŠ¡è¿è¡Œæ­£å¸¸</div>
            
            <h3>ç³»ç»Ÿä¿¡æ¯</h3>
            <div class="info">ğŸ–¥ï¸ è®¾å¤‡: jiangmen-pc</div>
            <div class="info">âš¡ è®¡ç®—è®¾å¤‡: {device_info}</div>
            <div class="info">ğŸ¯ GPU: {gpu_info}</div>
            <div class="info">ğŸŒ ç«¯å£: 8001</div>
            
            <h3>å¯ç”¨æ¥å£</h3>
            <div class="endpoint">
                <strong>GET /health</strong><br>
                å¥åº·æ£€æŸ¥æ¥å£
            </div>
            <div class="endpoint">
                <strong>POST /process</strong><br>
                å›¾åƒå»æ°´å°å¤„ç†ï¼ˆæ”¯æŒâ‰¤256pxå›¾åƒï¼‰<br>
                è¯·æ±‚æ ¼å¼: {{"input_path": "å›¾åƒæ–‡ä»¶è·¯å¾„"}}
            </div>
        </div>
    </body>
    </html>
    """

@app.route("/health", methods=["GET"])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "æ— GPU"
    return jsonify({"status": "ok", "device": "jiangmen-pc", "gpu": gpu_info, "mode": "gpu-cuda"})

@app.route("/process", methods=["POST"])
def process_image():
    """
    GPU åŠ é€Ÿå›¾åƒå»æ°´å°ï¼ˆä»…æ”¯æŒ â‰¤256px å›¾åƒï¼‰
    è¾“å…¥: {"input_path": "S:/images/frame_001.png"}
    è¾“å‡º: {"output_path": "S:/YDS-Lab/projects/dewatermark-ai/output/frame_001_clean.png"}
    """
    try:
        data = request.get_json()
        input_path = data.get("input_path")
        
        if not input_path or not os.path.exists(input_path):
            return jsonify({"error": "è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨"}), 400
        
        # é™åˆ¶è¾“å…¥å°ºå¯¸ï¼ˆé¿å…æ˜¾å­˜æº¢å‡ºï¼‰
        with Image.open(input_path) as img:
            if max(img.size) > 256:
                return jsonify({"error": "è¾“å…¥å›¾åƒè¿‡å¤§ï¼ˆ>256pxï¼‰ï¼Œè¯·ä½¿ç”¨è´µé˜³æœºå¤„ç†"}), 400
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        output_path = os.path.join(OUTPUT_DIR, f"{base_name}_clean.png")
        
        # è°ƒç”¨ GPU æ¨ç†ï¼ˆæ­¤å¤„ä¸ºå ä½é€»è¾‘ï¼‰
        log_to_general_office(f"æ±Ÿé—¨æœºå¯åŠ¨ GPU æ¨ç†: {input_path}", "operations")
        # å®é™…åº”è°ƒç”¨ model(input_tensor)
        shutil.copy(input_path, output_path)  # æ¨¡æ‹Ÿå¤„ç†
        
        log_to_general_office(f"âœ… æ±Ÿé—¨æœºå¤„ç†æˆåŠŸ: {output_path}", "operations")
        return jsonify({"output_path": output_path})
        
    except Exception as e:
        log_to_general_office(f"âš ï¸ æ±Ÿé—¨æœºå¼‚å¸¸: {str(e)}", "errors")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    # ç›‘å¬ 8001 ç«¯å£ï¼ˆé¿å…ä¸è´µé˜³æœºå†²çªï¼‰
    app.run(host="0.0.0.0", port=8001, debug=False)